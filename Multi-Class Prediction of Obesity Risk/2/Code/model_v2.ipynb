{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Label Encoding\n",
    "def label_encoder_target(data):\n",
    "    data = data.map({'Insufficient_Weight':0, 'Normal_Weight':1, 'Overweight_Level_I':2, 'Overweight_Level_II':3, 'Obesity_Type_I':4, 'Obesity_Type_II':5, 'Obesity_Type_III':6})\n",
    "    return data\n",
    "\n",
    "\n",
    "def encoder(data, label_col, label_col2, label_col3,label_col4, onehot_cols):\n",
    "    if label_col in data.columns:\n",
    "        data[label_col] = data[label_col].map({'Insufficient_Weight':0, 'Normal_Weight':1, 'Overweight_Level_I':2, 'Overweight_Level_II':3, 'Obesity_Type_I':4, 'Obesity_Type_II':5, 'Obesity_Type_III':6})\n",
    "    for col in onehot_cols:\n",
    "        if col != 'Gender':\n",
    "            data[col] = data[col].map({'yes':1, 'no':0})\n",
    "        else:\n",
    "            data[col] = data[col].map({'Female':0, 'Male':1})\n",
    "    \n",
    "    data[label_col2] = data[label_col2].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "    data[label_col3] = data[label_col3].map({'Bike':0, 'Walking':1, 'Public_Transportation':2, 'Motorbike':3, 'Automobile':4})\n",
    "    data[label_col4] = data[label_col4].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "    return data\n",
    "\n",
    "def decoder(data, label_col, label_col2, label_col3, label_col4, onehot_cols):\n",
    "    # Original mapping dictionary\n",
    "    reverse_mapping = {'Insufficient_Weight': 0, 'Normal_Weight': 1, 'Overweight_Level_I': 2, 'Overweight_Level_II': 3, 'Obesity_Type_I': 4, 'Obesity_Type_II': 5, 'Obesity_Type_III': 6}\n",
    "    # Reverse the mapping\n",
    "    reverse_mapping = {v: k for k, v in reverse_mapping.items()}\n",
    "    # Use the reversed mapping to decode\n",
    "    data[label_col] = data[label_col].map(reverse_mapping)\n",
    "\n",
    "    # Reverse mapping for onehot_cols\n",
    "    for col in onehot_cols:\n",
    "        if col != 'Gender':\n",
    "            data[col] = data[col].map({1: 'yes', 0: 'no'})\n",
    "        else:\n",
    "            data[col] = data[col].map({0: 'Female', 1: 'Male'})\n",
    "\n",
    "    # Reverse mapping for label_col2\n",
    "    data[label_col2] = data[label_col2].map({0: 'no', 1: 'Sometimes', 2: 'Frequently', 3: 'Always'})\n",
    "    # Reverse mapping for label_col3\n",
    "    data[label_col3] = data[label_col3].map({0: 'Bike', 1: 'Walking', 2: 'Public_Transportation', 3: 'Motorbike', 4: 'Automobile'})\n",
    "    # Reverse mapping for label_col4\n",
    "    data[label_col4] = data[label_col4].map({0: 'no', 1: 'Sometimes', 2: 'Frequently', 3: 'Always'})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# print(A.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135478222805865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#current working directory\n",
    "import os\n",
    "os.getcwd()\n",
    "setwd = os.chdir('/Users/arham/Downloads/Kaggle')\n",
    "\n",
    "onehot = ['Gender' ,'family_history_with_overweight','FAVC','SMOKE','SCC']\n",
    "\n",
    "\n",
    "\n",
    "# Load the labeled training data (A) and test data (B)\n",
    "A = pd.read_csv('train.csv')  \n",
    "B = pd.read_csv('test.csv')   \n",
    "S = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
    "\n",
    "# Perform encoding if needed\n",
    "# Assuming encoder and onehot functions are defined or imported properly\n",
    "A = encoder(A, 'NObeyesdad', 'CAEC', 'MTRANS', 'CALC', onehot)\n",
    "C = encoder(S, 'NObeyesdad', 'CAEC', 'MTRANS', 'CALC', onehot)\n",
    "B = encoder(B, 'NObeyesdad', 'CAEC', 'MTRANS', 'CALC', onehot)\n",
    "\n",
    "# Combine A and C to A \n",
    "A = pd.concat([A, C], axis=0)\n",
    "\n",
    "# Remove duplicates\n",
    "A = A.drop_duplicates()\n",
    "\n",
    "# split A into A and A_test\n",
    "A, A_test = train_test_split(A, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define scale_cols before scaling\n",
    "scale_cols = ['Age','Height', 'Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
    "\n",
    "# Min-max scaling \n",
    "for c in scale_cols:  \n",
    "    A[c] = A[c].pow(0.5)\n",
    "    B[c] = B[c].pow(0.5) \n",
    "    A_test[c] = A_test[c].pow(0.5)\n",
    "\n",
    "# Split the labeled training data into features (X) and target (y)\n",
    "X_train = A.drop(columns=['NObeyesdad'])  \n",
    "y_train = A['NObeyesdad']  \n",
    "\n",
    "# Define XGBClassifier with parameters # optuna  with 10 iterations\n",
    "parameters = {'max_depth': 6, 'learning_rate': 0.03617694379652588, 'n_estimators': 629, 'subsample': 0.8204774268264704, 'colsample_bytree': 0.8750737854215174}\n",
    "model = XGBClassifier(**parameters)\n",
    "\n",
    "# Fit the model on the entire dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(A_test.drop(columns=['NObeyesdad']))\n",
    "\n",
    "\n",
    "# accuracy\n",
    "\n",
    "accuracy = accuracy_score(A_test['NObeyesdad'], y_test_pred)\n",
    "# # Create submission DataFrame\n",
    "# submission = pd.DataFrame({'id': B['id'], 'NObeyesdad': y_test_pred})\n",
    "\n",
    "# # Decode NObeyesdad\n",
    "# reverse_mapping = {\n",
    "#     0: 'Insufficient_Weight',\n",
    "#     1: 'Normal_Weight',\n",
    "#     2: 'Overweight_Level_I',\n",
    "#     3: 'Overweight_Level_II',\n",
    "#     4: 'Obesity_Type_I',\n",
    "#     5: 'Obesity_Type_II',\n",
    "#     6: 'Obesity_Type_III'\n",
    "# }\n",
    "# submission['NObeyesdad'] = submission['NObeyesdad'].map(reverse_mapping)\n",
    "\n",
    "# # Save submission to CSV\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "# submission.to_csv(f'submission_{timestamp}.csv', index=False)\n",
    "\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
